# This is a basic workflow to help you get started with Actions

name: Deploy To Site

# Controls when the action will run.
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [master, next]

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v4
      - id: vars
        run: echo ::set-output name=short_ref::${GITHUB_REF#refs/*/}

      - uses: actions/setup-node@v4
        with:
          node-version: "20.0"

      - run: yarn install
      - run: yarn build

      - uses: docker/setup-buildx-action@v1
      - uses: docker/login-action@v1
        with:
          username: ${{ secrets.REGISTRY_USERNAME }}
          password: ${{ secrets.REGISTRY_TOKEN }}
          registry: registry.webix.io
      - uses: docker/build-push-action@v2
        with:
          context: .
          push: true
          tags: registry.webix.io/suite-docs-alt:${{ steps.vars.outputs.short_ref }}

      - run: curl "https://docs.dhtmlx.com/hooks/restart-docker?token=${{ secrets.RESTART_TOKEN }}&project=docs-suite-alt-${{ steps.vars.outputs.short_ref }}"

  algolia-crawl:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v4

      - name: Wait for Deployment
        run: sleep 30

      - name: Algolia Crawler Creation and Crawl
        uses: algolia/algoliasearch-crawler-github-actions@v1.0.10
        with:
          crawler-user-id: ${{ secrets.CRAWLER_USER_ID }}
          crawler-api-key: ${{ secrets.CRAWLER_API_KEY }}
          algolia-app-id: ${{ secrets.ALGOLIA_APP_ID }}
          algolia-api-key: ${{ secrets.ALGOLIA_API_KEY }}
          site-url: "https://docs.dhtmlx.com/suite/"
          crawler-name: "Suite Docs Crawler"
          override-config: true
